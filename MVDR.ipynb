{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.11.0+cu113\n",
      "0.11.0+cu113\n",
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import torch\n",
    "import torchaudio\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from natsort import natsorted\n",
    "\n",
    "import ci_sdr\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "torch.random.manual_seed(0)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(torch.__version__)\n",
    "print(torchaudio.__version__)\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class L3DAS_Task1_A_Dataset(Dataset):\n",
    "    def __init__(self, ddir: str):\n",
    "        super().__init__()\n",
    "        self.ddir = ddir\n",
    "        self.dAdir=natsorted(glob.glob(self.ddir+'/*/*/data/'  +'*_A.wav')) #Aは生データ Bは加工データ\n",
    "        self.dLdir=natsorted(glob.glob(self.ddir+'/*/*/labels/'+'*.wav'))\n",
    "\n",
    "    def __getitem__(self, index: int ):\n",
    "        ditem , sr1 = torchaudio.load(self.dAdir[index])\n",
    "        litem , sr2 = torchaudio.load(self.dLdir[index])\n",
    "        assert ditem.size(1) == litem.size(1)\n",
    "        assert sr1 == sr2\n",
    "        return ditem,litem\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return min([len(self.dAdir),len(self.dLdir)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MVDRBeamformer(pl.LightningModule):\n",
    "    def __init__(self,\n",
    "                  n_fft=1024,\n",
    "                  kernel_size=3,\n",
    "                  num_feats=16,\n",
    "                  num_hidden=64,\n",
    "                  num_layers=2,\n",
    "                  num_stacks=4,\n",
    "                  msk_activate=\"sigmoid\",\n",
    "                ):\n",
    "        super().__init__()\n",
    "        input_dim=(n_fft)//2 +1\n",
    "\n",
    "        self.maskgeneretor = torchaudio.models.conv_tasnet.MaskGenerator(\n",
    "            input_dim=input_dim,\n",
    "            num_sources=2,\n",
    "            kernel_size=kernel_size,\n",
    "            num_feats=num_feats,\n",
    "            num_hidden=num_hidden,\n",
    "            num_layers=num_layers,\n",
    "            num_stacks=num_stacks,\n",
    "            msk_activate=msk_activate\n",
    "        )\n",
    "        self.mvdr = torchaudio.transforms.MVDR(\n",
    "            ref_channel=0,\n",
    "            solution=\"stv_evd\",\n",
    "            multi_mask=True\n",
    "        )\n",
    "        self.stft = torchaudio.transforms.Spectrogram(\n",
    "            n_fft=n_fft,\n",
    "            hop_length=n_fft//4,\n",
    "            power=None,\n",
    "        )\n",
    "        self.istft = torchaudio.transforms.InverseSpectrogram(\n",
    "            n_fft=n_fft,\n",
    "            hop_length=n_fft//4,\n",
    "        )\n",
    "    \n",
    "    # 予測/推論アクションを定義\n",
    "    def forward(self, x):\n",
    "        spec = self.stft(x) #[c,t]->[c,f,t]\n",
    "        mask = self.maskgeneretor(spec.abs()) #[c,f,t]->[b*c,f,t]\n",
    "        stft_est = self.mvdr(spec, mask[:,0], mask[:,1])\n",
    "        est = self.istft(stft_est, length=x.shape[-1])\n",
    "        return est\n",
    "    \n",
    "    # train ループを定義\n",
    "    def training_step(self, batch, batch_idx):  #(ditems,litems)\n",
    "        x, y = batch  #[b,c,t]\n",
    "        spec = self.stft(x) #[b,c,t]->[b,c,f,t]\n",
    "        mask = self.maskgeneretor(spec.abs().view(-1,spec.size(2),spec.size(3))) #[b*c,f,t]->[b*c,f,t]\n",
    "        stft_est = self.mvdr(spec.view(-1,spec.size(2),spec.size(3)), mask[:,0], mask[:,1]) # ->[b*1,f,t]\n",
    "        stft_est = stft_est.view(-1,1,spec.size(2),spec.size(3))  #[b*1,f,t]->[b,c(=1),f,t]\n",
    "        est = self.istft(stft_est, length=x.shape[-1])\n",
    "        loss = ci_sdr.pt.ci_sdr_loss(est.to(torch.float32), y.to(torch.float32))\n",
    "        loss = torch.mean(loss)\n",
    "        self.log(\"train_loss\", loss, logger=True)\n",
    "        return loss\n",
    "    \n",
    "    # validation ループを定義\n",
    "    def validation_step(self, batch, batch_idx):  #(ditems,litems)\n",
    "        x, y = batch  #[b,c,t]\n",
    "        spec = self.stft(x) #[b,c,t]->[b,c,f,t]\n",
    "        mask = self.maskgeneretor(spec.abs().view(-1,spec.size(2),spec.size(3))) #[b*c,f,t]->[b*c,f,t]\n",
    "        stft_est = self.mvdr(spec.view(-1,spec.size(2),spec.size(3)), mask[:,0], mask[:,1]) # ->[b*1,f,t]\n",
    "        stft_est = stft_est.view(-1,1,spec.size(2),spec.size(3))  #[b*1,f,t]->[b,c(=1),f,t]\n",
    "        est = self.istft(stft_est, length=x.shape[-1])\n",
    "        loss = ci_sdr.pt.ci_sdr_loss(est.to(torch.float32), y.to(torch.float32))\n",
    "        loss = torch.mean(loss)\n",
    "        self.log(\"val_loss\", loss, logger=True)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n",
    "        return optimizer\n",
    "\n",
    "def generate_batch(batch):  #[b, getitem]\n",
    "    lengths = [entry[0].size(1) for entry in batch]\n",
    "    maxlen  = max(lengths)\n",
    "    ditems = torch.cat([F.pad(entry[0],pad=(0, maxlen-entry[0].size(1)),mode='constant',value=0)[None] for entry in batch])\n",
    "    litems = torch.cat([F.pad(entry[1],pad=(0, maxlen-entry[0].size(1)),mode='constant',value=0)[None] for entry in batch])\n",
    "    assert ditems.size(2)==litems.size(2)\n",
    "    return ditems,litems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = MVDRBeamformer().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddir = \"D:/Dataset/L3DAS_Task1_dev\"\n",
    "dataset = L3DAS_Task1_A_Dataset(ddir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l=dataset.__len__()\n",
    "t=l//5*4;v=l-t\n",
    "batch_size=4\n",
    "every_n_steps=16\n",
    "print(t,v,batch_size)\n",
    "\n",
    "train, val = random_split(dataset, [t, v])\n",
    "datat=DataLoader(\n",
    "    train,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=generate_batch,\n",
    "    # shuffle=True,\n",
    ")\n",
    "datav=DataLoader(\n",
    "    val,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=generate_batch,\n",
    "    # shuffle=True,\n",
    ")\n",
    "\n",
    "checkpoint_dir = 'train'\n",
    "checkpoint_callback = pl.callbacks.ModelCheckpoint(\n",
    "    monitor=\"val_loss\", \n",
    "    dirpath=checkpoint_dir,\n",
    "    filename=\"test-{epoch:04d}\",\n",
    "    every_n_train_steps=every_n_steps,\n",
    "    save_top_k=3,\n",
    "    mode=\"min\",\n",
    ")\n",
    "loggerTB=pl.loggers.TensorBoardLogger(checkpoint_dir+'/tb_logs', name='my_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer= pl.Trainer(max_epochs=1000,\n",
    "                    log_every_n_steps=every_n_steps,\n",
    "                    logger=loggerTB,\n",
    "                    callbacks=[checkpoint_callback],\n",
    "                    gpus=1,\n",
    "                    limit_train_batches=8,\n",
    "                    limit_val_batches=4,\n",
    "                    fast_dev_run=True,\n",
    "                    )\n",
    "trainer.fit(net, datat, datav)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net.state_dict(), 'models/model.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.load_state_dict(torch.load('models/1900_236_16_200.ckpt', map_location=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wa,sr=torchaudio.load('out/84-121123-0021_A.wav')\n",
    "wa=net.forward(wa).cpu().detach()[None]\n",
    "torchaudio.save(filepath='out/output.wav', src=wa, sample_rate=sr)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('MVDR')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "24998baa72c26d5bbb568017c7cc5db83a8d8efbdad7251f935f427666ef77b5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
